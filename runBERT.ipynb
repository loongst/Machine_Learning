{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "runBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqgeLl/515sKs8DHQjdHXi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loongst/Machine_Learning/blob/main/runBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ2ojJXQqLv3",
        "outputId": "3738ea2c-4054-4900-da8c-42b460b75eb1"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g4KV1CWZSLlpzLpLdBi-uEwGFZfoMR149TcZaavfnIjXS0heBlObMg\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsS8C7Y_xPuc",
        "outputId": "70d13c4b-b95e-4f75-adf1-8b241178de26"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar  8 12:32:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8WbjbIBrced",
        "outputId": "49c6b6e1-26cd-4e1c-91f6-24a71f59b341"
      },
      "source": [
        "import os\r\n",
        "path=\"/content/drive/MyDrive/DUTA/code\"\r\n",
        "os.chdir(path)\r\n",
        "os.listdir(path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Untitled0.ipynb',\n",
              " '.idea',\n",
              " 'requirements.txt',\n",
              " 'clean_text.py',\n",
              " 'bert.py',\n",
              " 'traditional_ML.py',\n",
              " '__pycache__']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR63DnRYsmF9",
        "outputId": "b93bb09e-5471-4e0d-8a21-1864fa971253"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhDxnFBDsezl",
        "outputId": "2984e6c3-a4e5-444e-e20b-e5e2d9b809ba"
      },
      "source": [
        "!python bert.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretrained Model: bert-base-uncased\n",
            "Device: cuda:0\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 326kB/s]\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "------------------------------\n",
            "Parameters:\n",
            "lr: 2e-06\n",
            "marks: _lr2e-06_epoch30_wd1e-05\n",
            "model: bert-base-uncased\n",
            "num_epochs: 30\n",
            "weight_decay: 1e-05\n",
            "------------------------------\n",
            "Downloading: 100% 433/433 [00:00<00:00, 288kB/s]\n",
            "Downloading: 100% 440M/440M [00:10<00:00, 43.8MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch [1/30], Step [117/3510], Train Loss: 1.9945, Valid Loss: 1.8956\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [2/30], Step [234/3510], Train Loss: 1.9086, Valid Loss: 1.8335\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [3/30], Step [351/3510], Train Loss: 1.8455, Valid Loss: 1.7603\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [4/30], Step [468/3510], Train Loss: 1.7811, Valid Loss: 1.6987\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [5/30], Step [585/3510], Train Loss: 1.7178, Valid Loss: 1.6556\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [6/30], Step [702/3510], Train Loss: 1.6018, Valid Loss: 1.5667\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [7/30], Step [819/3510], Train Loss: 1.4649, Valid Loss: 1.3530\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [8/30], Step [936/3510], Train Loss: 1.3548, Valid Loss: 1.2397\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [9/30], Step [1053/3510], Train Loss: 1.2451, Valid Loss: 1.1462\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [10/30], Step [1170/3510], Train Loss: 1.1355, Valid Loss: 1.0738\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [11/30], Step [1287/3510], Train Loss: 1.0513, Valid Loss: 0.9962\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [12/30], Step [1404/3510], Train Loss: 0.9670, Valid Loss: 0.9397\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [13/30], Step [1521/3510], Train Loss: 0.8899, Valid Loss: 0.8690\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [14/30], Step [1638/3510], Train Loss: 0.8126, Valid Loss: 0.8218\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [15/30], Step [1755/3510], Train Loss: 0.7474, Valid Loss: 0.7800\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [16/30], Step [1872/3510], Train Loss: 0.6835, Valid Loss: 0.7516\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [17/30], Step [1989/3510], Train Loss: 0.6233, Valid Loss: 0.7182\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [18/30], Step [2106/3510], Train Loss: 0.5745, Valid Loss: 0.6870\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [19/30], Step [2223/3510], Train Loss: 0.5202, Valid Loss: 0.6604\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [20/30], Step [2340/3510], Train Loss: 0.4695, Valid Loss: 0.6458\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [21/30], Step [2457/3510], Train Loss: 0.4217, Valid Loss: 0.6393\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [22/30], Step [2574/3510], Train Loss: 0.3829, Valid Loss: 0.6290\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [23/30], Step [2691/3510], Train Loss: 0.3438, Valid Loss: 0.6238\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [24/30], Step [2808/3510], Train Loss: 0.3078, Valid Loss: 0.6154\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [25/30], Step [2925/3510], Train Loss: 0.2741, Valid Loss: 0.6395\n",
            "Epoch [26/30], Step [3042/3510], Train Loss: 0.2462, Valid Loss: 0.6037\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [27/30], Step [3159/3510], Train Loss: 0.2197, Valid Loss: 0.5955\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Epoch [28/30], Step [3276/3510], Train Loss: 0.1950, Valid Loss: 0.6143\n",
            "Epoch [29/30], Step [3393/3510], Train Loss: 0.1734, Valid Loss: 0.6070\n",
            "Epoch [30/30], Step [3510/3510], Train Loss: 0.1590, Valid Loss: 0.5991\n",
            "Model saved to ==>  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "Finished Training!\n",
            "Model loaded from <==  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_metrics.pt\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Model loaded from <==  ../data/result/bert-base-uncased_lr2e-06_epoch30_wd1e-05_model.pt\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "Counterfeit Credit-Cards     0.9429    0.9167    0.9296        36\n",
            "          Cryptocurrency     0.9444    0.9808    0.9623       104\n",
            "                   Drugs     0.8889    0.9231    0.9057        26\n",
            "             Marketplace     0.8500    0.6800    0.7556        25\n",
            "                Personal     0.6667    0.5417    0.5977        48\n",
            "                   Porno     0.7391    0.9444    0.8293        18\n",
            "                Services     0.5294    0.4500    0.4865        20\n",
            "          Social-Network     0.5349    0.6571    0.5897        35\n",
            "\n",
            "                accuracy                         0.8045       312\n",
            "               macro avg     0.7620    0.7617    0.7570       312\n",
            "            weighted avg     0.8049    0.8045    0.8012       312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}